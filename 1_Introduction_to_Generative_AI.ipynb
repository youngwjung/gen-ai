{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5adba3d9",
      "metadata": {
        "id": "5adba3d9"
      },
      "source": [
        "# Deep Convolutional Generative Adversarial Network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5761769c",
      "metadata": {
        "id": "5761769c"
      },
      "source": [
        "해당 실습은 TensorFlow 공식 문서에 나오는 DCGAN 예제를 기반으로 작성되었습니다. https://www.tensorflow.org/tutorials/generative/dcgan"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b6a3b4",
      "metadata": {
        "id": "56b6a3b4"
      },
      "source": [
        "## GANs\n",
        "Generative Adversarial Networks(GANs)은 새로운 이미지를 생성하는 Generator(생성자)와 생성된 이미지가 진짜인지 가짜인지를 평가하는 Discriminator(판별자) 2개의 네트워크로 구성된다.\n",
        "![image.png](https://www.tensorflow.org/tutorials/generative/images/gan1.png)\n",
        "학습이 진행될수록 생성자는 더 진짜같은 이미지를 생성하게 되고, 판별자는 진짜와 가짜를 구분하는 능력이 향상되게 된다.\n",
        "![image-2.png](https://www.tensorflow.org/tutorials/generative/images/gan2.png)\n",
        "GANs 모델의 궁극적 목표는 생성자를 통해서 생성된 이미지를 판별자가 진짜로 인식하게 만드는 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bf933a7",
      "metadata": {
        "id": "4bf933a7"
      },
      "source": [
        "## 환경 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bY0BWhsk8s1m",
      "metadata": {
        "id": "bY0BWhsk8s1m"
      },
      "source": [
        "실습 환경 구동이 필요한 라이브러리 설치 및 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d0afdab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d0afdab",
        "outputId": "23dd6cb1-f970-431e-990e-edf3b6df3d99",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "!pip install imageio\n",
        "!pip install git+https://github.com/tensorflow/docs\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "802d3567",
      "metadata": {
        "id": "802d3567"
      },
      "source": [
        "##  데이터 불러오기\n",
        "고양이 얼굴 이미지 15,000개를 포함하는 데이터셋 (https://www.kaggle.com/datasets/spandan2/cats-faces-64x64-for-generative-models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76652755",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76652755",
        "outputId": "91f5a200-af4d-45c2-9a10-f60ccf927d54"
      },
      "outputs": [],
      "source": [
        "URL = 'https://youngwjung.s3.ap-northeast-2.amazonaws.com/labs/gen-ai/cats.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats.zip', origin=URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats')\n",
        "\n",
        "cat_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    PATH,\n",
        "    labels=None,\n",
        "    color_mode=\"grayscale\",\n",
        "    image_size=(64,64),\n",
        "    batch_size=256\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3778bdee",
      "metadata": {
        "id": "3778bdee"
      },
      "source": [
        "## 모델 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c319163",
      "metadata": {
        "id": "1c319163"
      },
      "source": [
        "생성자 및 판별자 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "127d5f78",
      "metadata": {
        "id": "127d5f78"
      },
      "outputs": [],
      "source": [
        "# Generator\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(16*16*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((16, 16, 256)))\n",
        "    assert model.output_shape == (None, 16, 16, 256)\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 16, 16, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 32, 32, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 64, 64, 1)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Discriminator\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[64, 64, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bd99d10",
      "metadata": {
        "id": "2bd99d10"
      },
      "source": [
        "모델 정확도 및 성능 최적화에 필요한 변수 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beb3c899",
      "metadata": {
        "id": "beb3c899"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0d7dc37",
      "metadata": {
        "id": "a0d7dc37"
      },
      "source": [
        "## 학습 방법 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef2114f1",
      "metadata": {
        "id": "ef2114f1"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 200\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([256, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)\n",
        "\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "460b0d48",
      "metadata": {
        "id": "460b0d48"
      },
      "source": [
        "## 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c202564",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "5c202564",
        "outputId": "732fa856-482d-42ea-f592-36c5deae423d"
      },
      "outputs": [],
      "source": [
        "train(cat_dataset, EPOCHS)\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56daa808",
      "metadata": {
        "id": "56daa808"
      },
      "source": [
        "## 생성된 이미지 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd7d8b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "cfd7d8b8",
        "outputId": "da42b3f0-a1f3-4464-a0e7-6a0f81b75ed9"
      },
      "outputs": [],
      "source": [
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
        "\n",
        "display_image(EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33aeb151",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "33aeb151",
        "outputId": "94e597e3-a562-4cee-921e-f605cba40772"
      },
      "outputs": [],
      "source": [
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file(anim_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "conda_tensorflow2_p310",
      "language": "python",
      "name": "conda_tensorflow2_p310"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
